{
 "cells": [
  {
   "cell_type": "code",
   "id": "4f9760a4-bfea-4def-a5be-1a00a4babba2",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "593b47bf",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "device='mps'\n",
    "pipeline = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", variant=\"fp16\", use_safetensors=True, torch_dtype=torch.float16).to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Directly using the pipeline",
   "id": "c11f6dfff285c5e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image = pipeline(prompt=\"A cat playing with a ball in the forest\", negative_prompt=\"deformed, ugly\",\n",
    "                 num_inference_steps=10, width=512, height=512).images[0]\n",
    "image"
   ],
   "id": "88a899599e2d9def",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using Compel, no weighting",
   "id": "cb1daf4d6b6d9d0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from compel import CompelForSDXL\n",
    "compel = CompelForSDXL(pipeline)\n",
    "\n",
    "conditioning = compel(\"A cat playing with a ball in the forest\")\n",
    "negative_conditioning = compel(\"deformed, ugly\")\n",
    "# you could also use batched input:\n",
    "# conditioning = compel([\"A cat playing with a ball in the forest\", \"deformed, ugly\"])\n",
    "# and then use conditioning.embeds[0:1] for positive and conditioning.embeds[1:2] for negative\n",
    "\n",
    "image = pipeline(prompt_embeds=conditioning.embeds, pooled_prompt_embeds=conditioning.pooled_embeds,\n",
    "                 negative_prompt_embeds=negative_conditioning.embeds, negative_pooled_prompt_embeds=negative_conditioning.pooled_embeds,\n",
    "                 num_inference_steps=10, width=512, height=512).images[0]\n",
    "image"
   ],
   "id": "1b45ee5e2452e8e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using Compel, with weighting",
   "id": "eab3393b016d9295"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from compel import CompelForSDXL\n",
    "compel = CompelForSDXL(pipeline)\n",
    "\n",
    "conditioning = compel(\"A cat playing with a ball++ in the forest\")\n",
    "compel = CompelForSDXL(pipeline)\n",
    "negative_conditioning = compel(\"deformed, ugly\")\n",
    "# you could also use batched input:\n",
    "# conditioning = compel([\"A cat playing with a ball++ in the forest\", \"deformed, ugly\"])\n",
    "# and then use conditioning.embeds[0:1] for positive and conditioning.embeds[1:2] for negative\n",
    "\n",
    "image = pipeline(prompt_embeds=conditioning.embeds, pooled_prompt_embeds=conditioning.pooled_embeds,\n",
    "                 negative_prompt_embeds=negative_conditioning.embeds, negative_pooled_prompt_embeds=negative_conditioning.pooled_embeds,\n",
    "                 num_inference_steps=10, width=512, height=512).images[0]\n",
    "image"
   ],
   "id": "b1bfce5e381b57cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Long prompts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a0aa04d1c6e3cd6"
  },
  {
   "cell_type": "code",
   "source": [
    "from compel import CompelForSDXL\n",
    "compel = CompelForSDXL(pipeline)\n",
    "\n",
    "prompt = \"a cat playing with a ball++ in the forest\"\n",
    "negative_prompt = \"a long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long long negative prompt\"\n",
    "\n",
    "# use batched input - Compel will automatically pad the shorter main prompt to the length of the longer negative prompt (or vice versa)\n",
    "# otherwise you'll hae to use `pad_conditioning_tensors_to_same_length` from `compel.utils`\n",
    "conditioning = compel([prompt, negative_prompt])\n",
    "print(conditioning.embeds.shape, conditioning.pooled_embeds.shape)\n",
    "\n",
    "image = pipeline(prompt_embeds=conditioning.embeds[0:1], pooled_prompt_embeds=conditioning.pooled_embeds[0:1],\n",
    "                 negative_prompt_embeds=conditioning.embeds[1:2], negative_pooled_prompt_embeds=conditioning.pooled_embeds[1:2],\n",
    "                 num_inference_steps=24, width=768, height=768).images[0]\n",
    "image"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e9941e0e42e76b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sequential cpu offload"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ed69a9a9e07eae8"
  },
  {
   "cell_type": "code",
   "id": "1685e7f8-1e41-46c1-92f8-9dcfec025db0",
   "metadata": {},
   "source": [
    "from compel import Compel, ReturnedEmbeddingsType\n",
    "\n",
    "compel = Compel(tokenizer=[pipeline.tokenizer, pipeline.tokenizer_2] , \n",
    "                text_encoder=[pipeline.text_encoder, pipeline.text_encoder_2], \n",
    "                returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED, \n",
    "                requires_pooled=[False, True],\n",
    "                device=\"cuda\")\n",
    "\n",
    "pipeline.enable_sequential_cpu_offload()\n",
    "prompt = \"a cat playing with a ball++ in the forest\"\n",
    "negative_prompt = \"deformed, ugly\"\n",
    "conditioning, pooled = compel([prompt, negative_prompt])\n",
    "\n",
    "image = pipeline(prompt_embeds=conditioning[0:1], pooled_prompt_embeds=pooled[0:1], \n",
    "                 negative_prompt_embeds=conditioning[1:2], negative_pooled_prompt_embeds=pooled[1:2],\n",
    "                 num_inference_steps=24, width=768, height=768).images[0]\n",
    "image"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Different prompts for different encoders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a96381af5bdb52b"
  },
  {
   "cell_type": "code",
   "source": [
    "from compel import CompelForSDXL\n",
    "compel = CompelForSDXL(pipeline)\n",
    "\n",
    "main_prompt = \"a cat playing with a ball++ in the forest\"\n",
    "style_prompt = \"forest ambience, high quality, detailed, intricate, artstation, 8k\"\n",
    "\n",
    "conditioning = compel(main_prompt=main_prompt, style_prompt=style_prompt)\n",
    "\n",
    "image = pipeline(prompt_embeds=conditioning.embeds, pooled_prompt_embeds=conditioning.pooled_embeds, num_inference_steps=30).images[0]\n",
    "\n",
    "image\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab10c0d2d52603c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Full manual control",
   "id": "6e284d27dc1f7620"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "compel1 = Compel(\n",
    "    tokenizer=pipeline.tokenizer,\n",
    "    text_encoder=pipeline.text_encoder,\n",
    "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "    requires_pooled=False,\n",
    ")\n",
    "\n",
    "compel2 = Compel(\n",
    "    tokenizer=pipeline.tokenizer_2,\n",
    "    text_encoder=pipeline.text_encoder_2,\n",
    "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "    requires_pooled=True,\n",
    ")\n",
    "\n",
    "conditioning1 = compel1(main_prompt)\n",
    "conditioning2, pooled = compel2(style_prompt)\n",
    "conditioning = torch.cat((conditioning1, conditioning2), dim=-1)\n",
    "\n",
    "image = pipeline(prompt_embeds=conditioning, pooled_prompt_embeds=pooled, num_inference_steps=30).images[0]\n",
    "image"
   ],
   "id": "4f3c8243c2ade101"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
